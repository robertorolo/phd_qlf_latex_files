Parte 1
=========

Slide 1
********

Um boa dia a todos, gostaria primeiramente de agradecer a presença de todos vocês, em especial doutor Diego, doutor Luís Eduardo, Professor João Felipe. 

Meu nome é Roberto Rolo sou engenheiro de minas, fiz meu mestrado aqui na UFRGS com o professor joão Felipe intitulado modelagem geológica implícita com funções distâncias assinaladas. 
Minha proposta de tese é uma extensão natural do trabalho desenvolvido no meu mestrado: eu proponho aprimoramentos em modelagem geológica implícita com funções distância assinaladas.

Slide 2
********

Nessa apresentação eu ser breve na introdução ao assunto modelagem geológica, vou falar sobre a metodologia tradicional, explícita, sobre métodos automáticos e modelagem implícita, dando destaque para a modelagem implícitas com funções ditância assinaladas.

Então vou apresentar o estado da arte em modelagem geológica implícita com distâncias assinaladas usando um banco de dados tridimensional pra mostrar a mecânica do método os diferentes métodos para avaliação de incerteza de modelos geológicos implícitos.

Depois disso eu vou apontar os principais problemas da metodologia e apresentar minha proposta de tese que tem como objetivo eliminar alguns desses problemas.

Slide 3
*********

Estimativas de recursos e reservas minerais demandam a construção de modelos numéricos de teores: 

* de longo prazo, que abrangem toda a extensão do depósito mineral e compreendem todo o tempo de vida da mina;

* Modelos de médio prazo para planejar de um a seis meses no futuro ;

* E  curto prazo pra balizar semanalmente ou diariamente as decisões relativas a controle de teores e planejamento mais detalhado da mina.

A construção desses modelos exige quatro grandes atividades:

* Coleta e gerenciamento de dados;

* Interpretação e modelagem geológica;

* Atribuição de teores;
 
* e Avaliação e gerenciamento da incerteza geológica e de teores.

O escopo dessa proposta tese está no passo 2: interpretação e modelagem geológica.

Slide 4
*********

Após a coleta, gerenciamento e checagem dos dados, é necessário identificar diferentes domínios. A determinação dos domínios deve ser baseada no conhecimento geológico, como zonas de oxidação, diferentes litologias, alteração ou limites estruturais e deve ser suportada por uma extensiva análise estatística e variográfica e pode ser baseada na combinação de uma ou mais variáveis.

A definição de diferentes domínios é necessária porque a inferência geostatística exige a decisão de estacionariedade. Os teores em cada domínio estacionários pertencem a populações estatística diferentes caracterizadas por seu modelo de distribuição de probabilidades (o histograma) e seu modelo de covariâncias (o variograma).

Uma vez que os domínios tenham sido definidos um modelo tridimensional que dene os limites de cada função aleatória estacionária deve ser construído. Esse é o modelo geológico: Ele define a jurisdição espacial de cada função aleatória. O modelo geológico é o alicerce para para todo o trabalho de estimativa subsequente e muitas vezes é o fator de maior importância na estimativa das tonelagens mineralizadas.

Slide 5
*********

Tradicionalmente os modelos geológico são construídos de forma explícita: o geomodelador digitaliza manualmente polilinhas em seções verticais e horizontais a partir dos dados de sondagem, as polilinhas são unidas por linhas guias e trianguladas gerando uma representação do sólido geológico.

Slide 6
********

Embora a metodologia tradicional seja direta e simples e que softwares de mineração forneçam ferramentas computacionais para agilizar o processo, ainda existem uma série de desvantagens e limitações:

* O processo é tedioso e demorado. Em depósitos de alta complexidade não é raro o geomodelador rabalhar por três meses no modelo geológico.

* Digitaliazar manualmente as polilinhas exige muito tempo de um profissional experiente;

* A geometria dos corpos geolóigcos muitas vezes precisa ser simplificada para que o modelo seja concebido em tempo hábil;

* O processo é subjetivo, Geomodeladores diferentes criam modelos geológicos diferentes a partir do mesmo banco de dados;

* Por esse motivo os modelos geológicos criados a partir do método tradicional não são replicáveis consequentemente não auditáveis;

* O método é inflexível, já que a meidida que novas amostras são obtidas, a atualização do modelo demanda nova gigitalização manual;

* Em muitas minas, talvez na grande maioria delas, apenas um modelo geológico é construído e mantido por questões de tempo. Assim não há a oportunidade de modelar interpretações geológicas alterantivas e comparar estimavas de recursos baseadas em diferentes modelos. Além da redigitalização manual não existe forma direta de incorporar múltiplas realizações possíveis para a localização dos limites entre os diferentes domínios no método tradicional.

Slide 7
*********

No interior dos domínios não existe incerteza relacionada ao modelo geoógico, No esquema do slide azul é azul e vermelho é vermelho, a incerteza é associada ao limite que separa os diferentes domínios. Sua definição, em sub superfície, é um mero palpite.

Em muitos casos a incerteza do modelo geológico pode ser uma fonte de incerteza crucial. Em depósitos de veio de ouro por exemplo, o volume mineralizado é um indicador economico vital do projeto e está diretamente ligado ao modelo geológico, ignorar a incerteza do modelo geológico pode ser devastador para o empredimento. A incerteza do modelo geológico DEVE ser avaliada. 

Slide 8
********

As desvantagens do método explícito impulsionaram a criação de métodos automáticos, ou pelo menos semi automáticos, de modelagem geológica. Para a criação de modelos determinísticos, podem ser utilizados desde métodos matemáticos mais simples como o vizinho mais próximo, ou geostatístico com a krigagem dos indicadores. 

Já a necessidade de avaliação da incerteza impulsionou o desenvolvimento de métodos estocásticos, baseados em múltiplas realizações equiprováveis do modelo geológico. Metodologias estabelecidas da geostatística clássica, baseadas no variograma, são a simulação sequencial dos indicadores, simulação gaussiana truncada e siulação plurigaussiana truncada. Outros métodos não baseados no variograma também foram desenvolvidos: simulação multi ponto, simulação baseada em objetos são os principais expoentes. 

Slide 9
**********

Uma outra família de métodos que impotaram técnicas da computação gráfica são os métodos implícitos. A idéia central é usar uma função implícita para demarcar regiões no espaço. 

Todos os métodos implícitos compartilham da mesma mecânica. A partir de dados esparsos que podem ser categorias, dados estruturais, podem ser em pontos ou linhas... Uma função implícita é derivada, o campo escalar, que têm um número infinito de isosuperfícies. Para visualizar o modelo geológico uma isosuperfície expecífica deve ser extraída desse modelo implícito, geralmente a isosuperfície 0.

O que difere os métodos implícitos é a função volume, que é interpolada para criação do modelo implícito. mallet propôs uma função volume cronológica, baseada na posição estratigráfica das unidades geológicas. Um outro método implícito, nascido na escola de minas da frança, usa co-krigagem de incrementos em campo potencial omitindo a função volume.

De longe a função volume mais comum é a função distância assinalada, aplicações desse método são encontradas por toda a literatura de interpolação de dados esparços. Na modelagem geológica o método é competente em capturar a geometria e extensão de corpos geológicos e tem sido aplicada com sucesso há mais de 10 anos na exploração mineral. Nos últimos anos vem ganhado espaço em diversos softwares comerciais o maior exemplo é o leapfrog.  

Parte 2
==========

Slide 10
**********

Nos próximos slides a modelagem geológica implícita com distâncias assinaladas é explicada passo a passo e os métodos para avaliação de inceteza disponíveis na literatura são apresentadas. 

Um banco de dados sintético que emula um depósito de cobre pórfiro é usado para exempleficar e comparar os métodos. São 72 furos, totalizando cerca de 3 mil amostras, distribuídas entre três categorias: uma rocha encaixante e duas intrusões: uma vertical e uma tabular com mrgulho. O slide mostra as proprções de cada litologia e uma vista em perspectiva das amostras.

Slide 11
**********

O primeiro passo é codificar as amostras em indicadores: uma amostra recebe o indicador 1 se pertencer ao domínio que está sendo modelado e 0 caso contrário. O slide mostra as amostras amostas codificadas em indicadores para as categorias 1, 2 e 3.

Slide 12
***********

O segundo passo é o cáculo das distâncias assinaladas: para cada ponto amostral, a menor distância euclideana até um outro ponto amostal que pertença à um indicador oposto é computada e atribuída aquele ponto. Com o sinal negativo caso pertença ao domínio que está sendo modelado e com o sinal positivo caso contrário.

Para o esquema do slide: pra essa amostra preta aqui em cima, ela não pertence ao domínio, então foi codificada com o indicador 0, eu vou computar então a menor distância entre ela e uma outra amostra codificada com o indicador oposto, uma amostra vermelha, que pertence ao domínio. são 12 metros, então essa amostra preta vai receber o valor 12 metros com o sinal positivo, porque não pertence ao domínio. Para a amostra vermelha, vou computar a menor ditância até uma amostra preta, que é essa daqui, 8 metros, então ela recebe 8 metros com o sinal negativo porque pertence ao domínio que está sendo modelado. E finalmente a ultima amostra preta está a 8 metros da vermelha, recebe 8 com o sinal positivo, porque está fora do domínio modelado.

Slide 13
***********

Esse slide mostra as distâncias assinaladas calculadas para as litologias 1, 2 e 3.

Slide 14
***********

Agora as distâncias calculadas precisam ser interpoladas, alguns dos métodos de interpolação, que eu vou detalhar daaqui a pouco, exigem uma função de covariância, que pode ser obtida a partir dos dados.

Aqui surge o primeiro problema do método: as distâncias assinaladas não são estacionárias, isso quer dizer que o variograma não se estabiliza em um patamar, ele cresce indefinidamente à medida que o lag aumenta, dificultando a inferência do alcance. Além disso, as distâncias apresentam um comportamento extremamaente contínuo, que torna difícil a indentificação de direções principais. Esse caráter contínuo das distâncias faz com que o modelo gaussiano seja o mais indicado pra ajustar os variogramas.

A literatura sugere alternativas:

* Treinar o vvariograma usando validação cruzada;

* Tentar modelera de fato os variogramas experimtnais;

* Calcular e modelar o variograma dos indicadores e transformá-los em um equivalente gaussiano;

* Inferir um modelo de covariância plausível visualmente, a partir das amostras ou mapas delineados.

Slide 15
**********

Esse slide mostra os variogramas das distâncias asssinaladas calculados e modelados a partir do modelo gaussiano para as três litologias. Aqui eu calculei o variograma estandarizado, Então defino o range na na variância igual a um, mas note que o valor da variância continua aumentando.

Slide 16
**********

Já esse slide mostra os variograma calculados e modelados a partir do modelo esférico para os indicadores de cada categoria. Em tese, os variogramas dos indicadores são mais fáceis de modelar esão estacionários. Mas na prática, muitas vezes os variogramas dos indicadores são mais ruidosos e menos estruturados do 	que o das das distâncias assinaladas.

Slide 17
***********

Além das alternativas sugeridas pela literatura para modelagem do variograma, aqui no laboratório a gente testou as tabelas de covariância: nesse método a partir dos dados eu crio um modelo base de covariância de onde é possível derivar, usando transformada de fourrier, a tabela de covariâcia qu epode ser usada no processo de estimativa ou simulação. 

Os resultados são promissores, torna o método completamente automático, sem nenhuma interferência do usuário. Porém, ainda existem alguns problemas operacionais com as tableas de covariância que nãopermitem uma aplicação geral pra qualquer tipo de depósito.

Slide 18
**********

Essas ditâncias calculadas e variografadas devem ser interpoladas para todos os nós de um grid. Embora os métodos implícitos sejam gridless, que dizer, eles não dependem de um grid, os algoritmos de extração de iso superfícice exigem que a propriedade exista em um grid regular.  

Para um número constante de amostras o tempo necessário para interpolar a função volume aumenta linearmente com o número de nós. Os parâmetros do grid, muitas vezes são determinados por parâmetros técnicos do projeto. Para a definição do modelo geológico é impotante que o grid possa reproduzir a menor estrutura geológica de interesse.

Essa imagem mostra um modelo geológico multi categórico em grids de diferentes resoluões: para as dimensões 15 por 10 parecem muito grosseiros e as categorias dos pontos amostrais não são reproduzidas, já a dimensão 25 por 15 eu ganho um pouco de resolução, mas as estruturas  ainda não tem uma forma geológica. Pra 50 por 35 as formas o modelo se suavizam, mas ainda tem algum serrilhado, 100 por 75 as formas estão bastante suaves e as categorias das amostras são reproduzidas. Pra 150 por 120 não parece haver significativa melhora em relação ao modelo anterior. 

Então é preciso encontrar um balanço entre resolução e tempo de interpolação, nesse caso algo entre 50 por 35 e 100 por 75, a resolução pode aumnetar a medida que o projeto avança e mais amostras são obtidas.

Slide 19
*********

Par aesse estudo de caso, dois grid foram criados, um grosso com aproximadamente 100 mil nós e um fino com aproximadamente 1 milhão de nós.

Slide 20
*********

Qualquer método de interpolação pode ser usado para as distâncias assinaladas, até mesmo métodos do inverso da distância produzem resultados realistas. A krigagem e as funções de bases radiais permitem incorporar informaçõ adicional através dos modelos de covariância, porém a literatura recomenda o uso de métodos globais, ouseja, que usa, todas as amostras em todas as estimativas.

Diferentes métodos de interpolação podem ser encontrados na literatura:

* housseini e deutcsh usaram iqd;

* SIlva usou krigagem ordinária global;

* Eu usei krigagem ordinária na minha dissertação;

* O Boisvert usa LVA kriging pra interpolar com anistropia local;

* e o jonh manchuck e o clayton propusera um novo método de interpolação que integra seções digitalizadas e amostras.

Slide 21
**********

Esse slide mostra o porquê  de usar métodos globais. O primeiro modelo foi interpolado por krigagem ordinária usando 40 amostras por estimaitva, e fica bem evidente o surgimento de artefatos, causados pel aestratégia de busca. O segundo modelo foi interpolado com 100 amostras por estimativa e mesmo assim ainda é possível observar artefatos no modelo. O último modelo foi interpolado por RBF, que é um método global e gera modelos suaves e livres de artefatos.


Slide 22
**********

Apesar de que nos métodos globais a matriz de covariâcias das amostras com elas mesmo só precise ser invertida uma vez, para bancos de dados volumosos isso ainda é uma tarefa que demanda um grande esformço computacional, então, é possível particionar o problema em problemas menores, sobrepostos, que são mais eficientes, e unir todas as partes.

Slide 23
*********

Essa tabela mostra um benchmark dos métodos de interpolação para o banco de dados apresentado, as distâncias foram interpoladas por diferentes métodos no grid grosso que tem 100 mil nós e no grid fino com 1 milhão.

Todos os algoritmos são da biblioteca GSLib e foram rodados em um notebook comercial high end, para as três categorias.

Eu queria destacar algus pontos: não é possível interpolar as distância no grid fino por krigagem global, mesmo com 16gb de ram. A krigagem ordinária no grid fino, isso para as três categorias, leva 45 minutos, enquanto o RBF leva apenas pouco mais de um minuto, ainda é possível reduzir esse tempo particionando o grid.

Não é difícil perceber porque o RBF é o método preferido para interpolação de distâncias assinaladas, além de produzir modelos suaves, desejáveis nesse contexto de modelagem geológica, é 10 vezes mais rápido que a krigagem.

A Leapgfrog tem um algoritmo de rbf patenteado, chamado fast rbf, que é ainda mais rápido.

Slide 24
**********

O modelo implícito, que é função distância interpolada, tem infinitas iso usperfícies, pra visualizar o modelo geológico eu preciso extrair uma dessas superfície, e o melhor palpite pra onde se localiza a interface é a iso superfície zero. esse slide mosra a isosuperfície zero extraída, usando o algoritmo de cubos marchantes no software paraview, para a categoria 1. A partir dos modelos implícitos apresentados anteriormente. krigagem ordinária com 40 amostras, 100 amostras e rbf.

É possível observar que os artefatos dos modelos implícitos são transferidos para as isosuperfícies, e que métodos globais que geram modelos suaves, naturalemtne geram iso superfícies suaves, que apresentam realismo geológico.

Slide 25
***********

Esse slide mostra dias vistas diferentes da iso superficie zera extraida do modelo implicita interpolado por rbf para a categoria 1, unto com as amostras. Além de criar modelos realistas o rbf honra as amotras.

Slide 26
**********

E o mesmo para a categoria 2.

Slide 27
*********

Silva e Deutsch propuseram uma adaptação para o método para modelar múltiplas categorias simultânemanete. Se existirem K multiplos dominios no depósito mineral as amostras devem ser codificadas em indicadores K vezes, as distâncias assinaladas devem ser calculadas para as K categorias, As K propriedades distâncias asssinaladas devem ser interpoladas para um mesmo grid, e a categoria responsável pela menor distância assinalada, a mais negativa, deve ser retida no local não amostrado.

Slide 27
**********

Esse slide mostra um esquema da modelagem geológica implícita para múltiplos domínios simultâneos: nas bases dos gráficos estão as amostras, no nivel superior a projeção das distâncias assinaladas interpoladas, para categoria 1 as distancias são negativas onde tem amostra da categoria 1, que ;e na parte central da área. mema coisa para as categorias 2, 3 e 4. Pra cirar o modelo geológico é só reter a categoria responsável pela menor distância. na região central é a categoria 1, na parte noroeste a 3 nordeste a 4 e em volta do centro a categoria 2.

Slide 28
************

Esse slide mostra 4 seções em xy e 4 seções em yz do modelo implicito multi categórico para o banco de dados do estudo de caso.

Slide 29
**********

Corpos geológicos podem ser bastante complexos E modelá-los considerando estacionariedade de segunda ordem, quer dizer, a função de covariância é estaciária, então a mesma anisotropia vale para toda região, pode ser muito restritivo.

Uma alternativa é interpolar as distâncias por krigagem com anisotropia local variável, nesse método, para cada bloco a anisotropia local é derivada, então as distâncias são interpoladas por krigagem ordinária. Esse método pode demandar bastante esforço computacional já que em cada bloco a anistropia local deve ser calculada. 

Slide 30
***********

Esse slide mostra os vetores de anostropia local em todos os um milhão de blocos do grid fino e a iso superfície extraída para a categoria 1, e ao lado mostrando um vetor a cada 10.000 blocos.

Slide 31
***********

Pra o fluxo de trabalho usando RBF também é possível implementar não estacionariedade de segunda ordem, baseado no particionamento do domínio que eu mostrei alguns slides pra trás. Dessa forma, pra cada partição a anistropia local é derivada. Esse método demanda menos esforço computacional, já que os vetores de anisotropia não precisam ser calculados para cada bloco.

Slide 32
**********

Esse slide mostra os vetores de anostropia local para cada partição e a iso superfície extraída para a categoria 1.

Slide 33
**********

Pra obter resultados melhores é possível derivar os vetores de anisotropia local, interpolar as distâncias usando essa anisotropia local, então a partir das distâncias interpoladas, derivo novamente a anisotropia local e interpolo novamente, esse processo iterativo continua até que um cirtétio de parada pré estabelecido seja atingido.

a imagem mostra uma dobra em que os flancos vão se definindo com as iterações. Apesar de ser um método iterativo, ele é bastante eficiente porque o critério de parada pode ser atingido em diferentes iterações em cada partição.

Slide 34
***********

Ainda no assunto interpolação, o jonh manchuck e o proferssor clayton desenvolveram uma metodologia para incorporar seções digitalizadas na modelagem implícita. Para isso as distancias mais seções digitalizadas devem ser interpoladas por mínimos quadrados móveis. Porém, o método ainda é recente e segundo os autores ainda apresenta alguns problemas operacionais.

Slide 35
**********

Os próximos slides vão apresentar os métodos de avaliação de incerteza disponíveis na literatura e comentar um pouco sobre as características de cada um deles. 

O método mais simples, é uma avaliação heirística da incerteza, porque não é baseado em múltiplas realizações. Consiste em transformar as distâncias em probabilidades. na equação para calcular a probabilidade da categoria k no local não amostrado i, o d* é a ditância estimada para a categoria k e gamma é um parametro que controla a incerteza. Quanto maior gamma maior a diferença entre as probabilidades calculadas. 

o grafico de barras mostra as ditâncias assinaladas interpaladas para um bloco em particular, e ao lado as distâncias transformadas em probabilidades, quanto menor a distância, quanto mais negativa, maior a probabilidade. 

Esse é um método bem simples, rápido e direto e funciona pra multiplas categorias simultâneas. Em contrapartida, a escolha do parâmetro gamma é subjetiva, alguns autores indicam que seja a amior distância estimada entre todas as categorias, e dependendo do gamma escolhido nem blocos co locados com amostras recebem prbabilidade 100%.

Slide 36
***********

O próximo método, aumentando um pouco a complexidade, consiste, primeiramente em realizar um bootstrap espacial da média da distância assinalada, o bootstrap espacial só leva em consideração amostras não correlaciadas. Assim eu tenho um histograma da média, que é mostrado no slide, a partir desse histograma eu posso tomar valores, como o p10, p50 e p90 por exemplo, e intepolar as ditâncias assinaladas por krigagem simples, usando esses valores tomados como média. Em tese, eu poderia extrair diferentes iso superfícies zero dos modelos interpolados com diferentes médias. 

Porém na prática, dependendo da configuração espacial das amostras a krigagem simples não é sensível à media, para a categoria do banco de dados do estudo de caso, a diferença de volume entre as isosuperficies extraidas do modelo p10 e p90 é menor que 1%. O método não avalia adequadamente a incerteza, além disso, trabalha com uma categoria por vez, na presença de múltiplos domínios é necessário uma abordagem heirárquica.

Slide 37
***********

O próximo método é a primeira ideia que surge em mente em relação à avaliação de incerteza de modelos geológicos implícitos: a simulação direta das distâncias. 

O primeiro passo é calcular um coeficiente U de incerteza. Antes de qualquer coisa eu preciso criar uma lista com as menors distâncias interpoaldas em cada bloco. Então pra cada bloco eu eu subtraio do valor maximo dessa lista a menor distância estimada naquele bloco. O denominador é pra estandardizar entre 0 e 1.

Slide 38
***********

Esse slide mostra 4 seções verticais do coeficiente U, esse coeficiente basicamente delinea os contatos, ele é mais próximo de 1 onde há mais incerteza e mais próximo de zero onde não há.

Agora é necessário fazer uma truncagem entre 0 e 1 no coeficiente U pra delimitar uma zona e incerteza, quanto mais perto de 1 mais estreita é a zona de incerteza. As distâncias não precisam ser simuladas em todos os nós do grid, porque no interior dos domínios não há incerteza.

Slide 39
***********

Esse slide mostra uma realização das distâncias simuladas na zona de incerteza pra cada uma das litologias do banco de dados.

Os blocos fora da zona de incerteza ficam congelados, e recebem a a categoria respons;avel pela menor ditânca estimada, enquanto os blocos na zona de incerteza recebem a categoria responsável pela menor distância simulada, em cada realização.

Slide 40
***********

Esse slide mostra seções verticais de duas realizações do modelo. É possível observar nas regiões destacas bastante ruído, que gera formas não realistas. Além disso, em muitos casos, não existe um bom encaixe entre os blocos congelados e os blocos simulados. A simulação é muito sensível aos parâmetros e a zona de incerteza definida só serve pra dimuir o numero de blocos simulados, os limites dos modelos dependem somente dos parâmetros do algoritmo de simulação. 

Porém o método trabalha com múltiplas categorias e é baseado em múltiplas realizações, o priduto final pode ser usado nas proximas etapas da avaliação de recursos e planejamento mineiro.

Slide 41
***********

Além das desvantagens apresentadas o método possui um número execivo de passos:

As distancias devem ser calculadas pra cada litogia, variogradas e interpoaldas. Um modelo deterministico baseado na menor distancia deve ser criado, com base nas distancias interpoladas posso calcular o parametro u e definir a zona de incerteza, entao as distancias devem ser transfomradas para o espaco gaussiano, variografadas no espaco gaussiano, simuladas na zona de incerteza, retro transformadas e validadas. Aí sim posso gerar as realizações do modelo geológico baseadas na menor ditância simulada.

É difícil justificar a escolha desse método.

Slide 42
**********

Em sua tese de doutorado silva propôs integrar modelagem geológica implícita com simulação multi ponto. No seu trabalho ele propõe integrar múltiplas imagens de treinamento, uma metodologia pra calibrar a contribuição de cada TI e uma medida de entropia multi ponto ao longo dos furos. O esqueleto do método é criar uma TI a partir dos dados, que ele chama de data driven training image, usando funções distância assinaladas e aplicar MPS nessa TI.

O slide mostra seções verticais de uma das realizações de um modelo criado usando essa metodologia no banco de dados do estudo de caso. As formas são geológicas, os modelos não apresentam ruído excessivo, além disso, o método não depende de muitos parâmetros. Em contra partida, não é possível definir uma zona de incerteza para que os contatos variem em seu interior, tampouco controlar a natureza dos contatos.

Slide 43
***********

O próximo e último método, é o que produz os melhores resultados e o que tem sido mais usado pra avaliação de incerteza de modelos geológicos implíocitos. O primeiro passo é calibrar um parâmetro de incerteza de C. A calibração é feita por um método similar ao jacknife. 

O parametro C é uma constante que vai ser somada às distâncias positivas e subtraído das distâncias negativas, isso faz com a diferença entre os valores das distâncias seja maior, é como se eu tivesse abrindo o histograma das distancias.

Eu começo a calibração com c =0, então as distancias não estão modificadas ainda. Eu defino uma proporção de furos do banco de dados pra ser removida, pra categoria 1 do banco de dados do estudo de caso eu escolhi 25%. Então eu removi do banco de dados, aleatoriamente, 25% dos furos, 50 vezes, gerando 50 bancos de dados diferentes. Que são os pontos verticais no x=0. Então eu vou estimar a distância assinaladas onde eu removi as amostras, e checar se eu acerto se pertence ou não ao domínio, quer dizer se eu acerto o sinal da amostra, não estou interessado no valor da distância assinalada. Aí eu marco no eixo y, o índice de amostras classificadas de forma errada, pra cada um dos 50 banco de dados. 

Então eu inceremento C, nesse exemplo o c variou de 0 ate 250, e repito o processo. quanto maior for C, menor vai ser o indice de classificação errônea.
A partir dos resultados da calibração eu preciso escolher um valor de C. Alguns autores dizem que deve ser o valor reponsavel por 2,5% de classificação errônea, outros autores dizem que deve ser o valor de C onde a curva se estabiliza. Aqui eu tomei o valor 130, que corresponde a 2% de classificação errônea.

Slide 44
*************

A partir do valor escolhido para C, eu modifico as distâncias calculadas, somando C às distâncias positivas e subtraindo C das distâncias negativas.

Então essas distâncias modificadas são interpoladas para todos os nós do grid, uma truncagem no modelo interpolado deve ser feita entra -c e +c pra definir a zona de incerteza.

Na zona de incerteza eu realizao uma simulação gaussiana não condicional, o variograma pode ser o mesmo usado para interpolar as distâncias assinaladas. Para tornar a simulação gaussiana entre +c e -c dve ser tomado su valor acumulado, multiplicado por 2c e subtraído de C.

Slide 45
***********

Agora finalmente eu posso classificar os blocos comparando as distâncias assinaladas modificadas com a simulação não condicional, blocos onde a simulação é menor que a interpolação não pertencem ao domínio enquanto blocos em que a simulação é maior que a interpolação, pertencem ao domínio.

Slide 46
***********

Esse slide mostra as distâncias interpoladas na zona de incerteza para a categoria 1, as distancias simuladas na zona de incerteza, e os blocos classificados comparando ditancias intepoladas e simuladas.

Slide 47
************

O próximo slide mostra seções verticas em xy e xz de uma das realizações para a categoria 1. É possível observar que não há presença de ruído, as formas são suaves e realistas, além disso, ao contrário da simulação direta das distâncias, aqui o contato varia dentro da zona de incerteza, se a zona for larga a posição do contato e consequente o volume do solido vai ter grabnde variação, se for estrito terá pouca variação, o variograma controla a natureza do contato, um range maior produz contatos suaves enquanto ranges menores e efeito pepita produzem contatos rugosos. Apesar dessas vantagens a escolha do C pode ser subjetiva, e o método trabalha de forma binária, uma litologia por vez.

Slide 48
**********

Aqui no laboratório nós desenvolvelmos uma metodologia pra trabalhar com múltiplas categorias simultânes de forma hierárquica, porém a escolha dos gruipos é subjetiva e depende de conhecimento a respeito da gênese do depósito.

Slide 49
***********

Essa tabela mostra um sumário dos métodos de avaliação de incerteza apresentados, o método heuristico é simple's, rápido, multi categorico, porem nao produz modelo com realismo geologico, mas controla a incerteza por meio do parametro gamma mas nao o tipo de contato.

o metodo boundsim é simples, rapido, não trabalha com diferentes categorias, não apresenta realismo geologico, em tese seria possivel controlar a incerteza tomando diferentes valores para a media, mas isso nao acontece na pratica, tambe, nao é possivel controlar o tipo de contato.

A simulacao direta das distancias é um metodo complexo e demorado que trabalha com multiplas categorias simultaneamente porem nao apresenta realismo geologico nem permite o controle do tipo de contato, mas permite controlar a incerteza por meio dos parametros da simulacao.

O metodo que mescla mps com modelagem implicita é simples rapido, multicategorico apresenta realismo geologico mas nao permite controlar a incerteza nem o tipo do contato.

FInalmente o ultimo método, bounmdary simulation, é simples, rapido ja que a simulacao nao é condicional, nao é multi categorico mas apresenta realismo geologico, permite controle da incerteza e do tipo de contato. é o método que marca mais checkboxes disponivel na literatura.

Isso encerra o estado da arte e os próximos slides tratam da minha proposta de tes

Parte 3
==========

Slide 50
************

Embora a modelagem geoógica implícita seja um método consagrado que vem sendo usado com sucesso há mais de uma década, a metodologia apresenta alguns problemas pontuais:

* o ponto mais critico, que todos os revisores de artigo questionam e é uma dificuldade prática pra quem usa método também é a não estacionariedade das distâncias, que torna a modelgaem do variograma questionável;

* A escolha dos parametros do grid pode ser subjetiva;

* Assim como a escolha do interpolaor;

* Na presença de multiplos dominios, para geologias complexas, simplesemnte tomar a menor distância não produz bons resultados, é necessário uma abordagem hierárquica baseada na gênese do depósito;

* Nos métodos de avaliação de incerteza que usam algum tipo de zona de incerteza, muitas vezes, essa zona não é de fato incerta, existem amotras dentro das zona;

* Estruturas geológicas específicas, como lentes, diques, falhas, odbras, podem não ser reproduzida ou desaparecerem dos modelos;

* é necessário checar se os modelos implítos honram a geologia do depósito e serão úteis nas fases seguntes do processo de avaliação de recursos.

Slide 51
**********

O primeiro aprimoramento que essa tese propões é um novo interpolador para as distâncias assinaladas. 

Redes neurais são baseadas em neurônios, e usadas tipicmente em problemas de identificação.

Esse slide esquematiza uma rede neural. Os nós x na camada um da rede representam os inputs, os nós a na camada dois e três representam as camadas escondidas e a camada 4 é o nó de output e representa a hipótese.

As redes neurais trabalham em um sistema binário de zeros e uns e por isso podem se basear nas propriedades da função sigmoide, que tem seu valor em y entre zero e um para qualquer valor de x. Em uma rede neural uma hipótese é gerada para cada nó e é determinado se seu valor será zero ou um, um valor binário é passado para a próxima camada.


Slide 52
**********

Samson e deutsh propuseram um algoritmo usando tensor flow, que é uma biblioteca da google de código aberto para aprendizado de máquina, para implementar a arquitetura da rede neural. O método é baseado em aprendizado não supervisionado, com o algorito k means e supervisionado com uma rede neural de bases radiais.

Redes neurais de bases radiais apresentam uma arquitetura semelhante as redes neurais artificais, a primcipal diferença é que nas redes neurais de bases radiais só há uma camada escondida e a função de ativação é uma função de base radial ao invés de uma função sigmoide.

Em seu trabalho os autores dividiram o banco de dados em 2/3 para treinamento e 1/3 para teste. Usaram o algoritmo k-means pra determinar o numero de unidades de bases radiais na rede neural. A função de ativação alimentou o algoritmo com coordenadas x, y e z e teores das 5 amostras mais próximas do local a ser estimado.

As imagens mostram mostram a realidade estimativas por krigagem simples e estimativas pelo metodo proposto, que reprodu as caracteristicas visuais da imagem de referencia bem como o variograma e histograma.

Esse algoritmo resolve o problema do interpolador e do variograma ja que essa tecnica nao exige calculo e modelagem da covariância. A pesqusa de samsom e deutsch ainda está em seus estágios iniciais, els nao treinaram o parametro beta da funcao de base radial por exemplo. 

Essa técnica tem um potencial enorme de aplicação na modelagem geológica implicita, porque evita a modelagem do variograma e a escolha de um interpolador. Além disso a função radial gaussiana já é a mais indicada e utilizada com sucesso na interpolação das distâncias. O método ainda pode evoluir para um algoritmo de simulação pra avaliar incerteza dos modelos gelógicos.

Slide 53
************ 

Um outro objetivo dessa tese é desenvolver uma metodologia objetiva e direta para a definição da zona de incerteza. Ás metodologias disponíveis na literatura podem gerar zonas de incerteza em interseçao com amostras.

É necessário definir essas zonas de incerteza porque eu não preciso simular o grid inteiro, reduzindo o tempo e o esforço computacional e além disso, o método de avaliação de incerteza proposto nessa tese depende de diretamente da largura da zona de incerteza, os contatos variam em seu interior, zonas de incerteza maiores gera maior variação de volume dos corpos geológicos.

A ideia central da metodologia proposta é a entropia, que é calculada como: menos o somatório do produto da probabilidade de cada de cada litologia pelo logaritmo da probabilidade. Dessa forma, a entropia pode ser vista como uma medida da incerteza. 

suponha dois blocos e as probabilidades deles pertecerem a cada uma de três litologias, as probabilidades podem ser facilmente calculadas transformando distâncias estimadas em probabilidades, como mostrado no método heurístico de avaliação de incerteza. A entropia do primeiro bloco é baixa, já que a a categoria 1 tem probabilidade 80% enquanro a entropia do bloco 2 é alta, porque todas as categorias têm probabilidades similares.

Slide 54
***********

A transformação das distâncias em probabilidades envolve um paâmetro gamma, que contrala a incerteza, esse slide mostra duas seções verticais da entropia calculada para o banco de dados do estudo de caso, com dois valores de gamma diferentes. 

O desafio é desenvolver uma metodologia para calibrar o parametro gamma, de forma que onde existam amostras a entropia seja máxima.

depois de calcular a entropia, uma truncagem deve ser realizada para definição da zona de incerteza. Essa truncagem pode ser baseada no tipo de depósito, depositos com menor entropia de formação, como de bauxita, por exemplo, terão uma zona de incerteza mais estreita. enquanto depositos com alta entropia de formação, como os de ouro, terão zonas de incertezas mais largas.

Slide 55
***********


